{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING MODEL ARTIFACTS\n",
      "================================================================================\n",
      "âœ… Model loaded\n",
      "âœ… Preprocessor loaded\n",
      "âœ… Config loaded\n",
      "âœ… Features loaded\n",
      "\n",
      "âœ… Model ready for deployment\n",
      "   Version: 20251107_0700\n",
      "   Threshold: 0.3\n",
      "âœ… Model v20251107_0700 loaded\n",
      "   Threshold: 0.3\n",
      "   Features: 57\n",
      "\n",
      "================================================================================\n",
      "TESTING PREDICTION PIPELINE\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Test Sample Performance:\n",
      "Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1000\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "\n",
      "ðŸ“‹ Sample Predictions:\n",
      "    county  risk_probability risk_level  is_high_risk\n",
      "0  samburu          0.055635        Low             0\n",
      "1  samburu          0.056211        Low             0\n",
      "2  samburu          0.056211        Low             0\n",
      "3  samburu          0.056211        Low             0\n",
      "4  samburu          0.056211        Low             0\n",
      "5  samburu          0.056211        Low             0\n",
      "6  samburu          0.056211        Low             0\n",
      "7  samburu          0.056211        Low             0\n",
      "8  samburu          0.056211        Low             0\n",
      "9  samburu          0.056211        Low             0\n",
      "\n",
      "================================================================================\n",
      "TESTING ACTION RECOMMENDER\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Sample Recommendations (SME):\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['index', 'risk_probability', 'action_1', 'action_2'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 358\u001b[0m\n\u001b[0;32m    356\u001b[0m recommendations_sme \u001b[38;5;241m=\u001b[39m recommender\u001b[38;5;241m.\u001b[39mrecommend(predictions\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m20\u001b[39m), persona\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSME\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ“‹ Sample Recommendations (SME):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 358\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mrecommendations_sme\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrisk_probability\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maction_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maction_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m    360\u001b[0m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;66;03m# SECTION 5: CREATE TIERED ALERT SYSTEM\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_tiered_alerts\u001b[39m(predictions, budget_tiers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-216\\lib\\site-packages\\pandas\\core\\frame.py:4119\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4118\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4119\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4121\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-216\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6210\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6212\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6214\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6216\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-216\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6261\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6261\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6263\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['index', 'risk_probability', 'action_1', 'action_2'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DEPLOYMENT PREPARATION NOTEBOOK\n",
    "# ============================================================================\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 1: LOAD MODEL ARTIFACTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING MODEL ARTIFACTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Specify model version (use latest)\n",
    "MODEL_VERSION = \"20251107_0700\"  # Update with your version\n",
    "\n",
    "# Load model\n",
    "model = joblib.load(f'../models/rf_tuned_final_v{MODEL_VERSION}.pkl')\n",
    "print(\"âœ… Model loaded\")\n",
    "\n",
    "# Load preprocessor\n",
    "preprocessor = joblib.load(f'../models/preprocessor_v{MODEL_VERSION}.pkl')\n",
    "print(\"âœ… Preprocessor loaded\")\n",
    "\n",
    "# Load config\n",
    "with open(f'../models/model_config_v{MODEL_VERSION}.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "print(\"âœ… Config loaded\")\n",
    "\n",
    "# Load feature names\n",
    "with open(f'../models/feature_names_v{MODEL_VERSION}.json', 'r') as f:\n",
    "    feature_config = json.load(f)\n",
    "cat_features = feature_config['categorical']\n",
    "num_features = feature_config['numerical']\n",
    "print(\"âœ… Features loaded\")\n",
    "\n",
    "THRESHOLD = config['threshold']\n",
    "print(f\"\\nâœ… Model ready for deployment\")\n",
    "print(f\"   Version: {MODEL_VERSION}\")\n",
    "print(f\"   Threshold: {THRESHOLD}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 2: CREATE PREDICTION PIPELINE CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class OutageRiskPredictor:\n",
    "    \"\"\"\n",
    "    Production-ready outage risk predictor.\n",
    "    \n",
    "    Usage:\n",
    "    ------\n",
    "    predictor = OutageRiskPredictor()\n",
    "    predictor.load_model(model_version='20250108_1430')\n",
    "    predictions = predictor.predict(new_data)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.preprocessor = None\n",
    "        self.config = None\n",
    "        self.feature_names = None\n",
    "        self.threshold = None\n",
    "        \n",
    "    def load_model(self, model_version=None, models_dir='../models'):\n",
    "        \"\"\"Load model artifacts\"\"\"\n",
    "        if model_version is None:\n",
    "            # Auto-detect latest version\n",
    "            import glob\n",
    "            model_files = glob.glob(f'{models_dir}/model_config_v*.json')\n",
    "            if not model_files:\n",
    "                raise FileNotFoundError(\"No model found\")\n",
    "            latest_config = max(model_files)\n",
    "            model_version = latest_config.split('_v')[1].replace('.json', '')\n",
    "        \n",
    "        # Load artifacts\n",
    "        self.model = joblib.load(f'{models_dir}/rf_tuned_final_v{model_version}.pkl')\n",
    "        self.preprocessor = joblib.load(f'{models_dir}/preprocessor_v{model_version}.pkl')\n",
    "        \n",
    "        with open(f'{models_dir}/model_config_v{model_version}.json', 'r') as f:\n",
    "            self.config = json.load(f)\n",
    "        \n",
    "        with open(f'{models_dir}/feature_names_v{model_version}.json', 'r') as f:\n",
    "            feature_config = json.load(f)\n",
    "            self.feature_names = feature_config['all_features']\n",
    "        \n",
    "        self.threshold = self.config['threshold']\n",
    "        \n",
    "        print(f\"âœ… Model v{model_version} loaded\")\n",
    "        print(f\"   Threshold: {self.threshold}\")\n",
    "        print(f\"   Features: {len(self.feature_names)}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, return_probabilities=True):\n",
    "        \"\"\"\n",
    "        Make predictions on new data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pd.DataFrame\n",
    "            Input features (must have all required features)\n",
    "        return_probabilities : bool\n",
    "            If True, return probabilities; else return binary predictions\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame with columns:\n",
    "            - risk_probability (0-1)\n",
    "            - risk_level (Low/Medium/High)\n",
    "            - is_high_risk (binary at threshold)\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not loaded. Call load_model() first.\")\n",
    "        \n",
    "        # Validate features\n",
    "        missing = set(self.feature_names) - set(X.columns)\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing features: {missing}\")\n",
    "        \n",
    "        # Select features in correct order\n",
    "        X_selected = X[self.feature_names]\n",
    "        \n",
    "        # Predict probabilities\n",
    "        probabilities = self.model.predict_proba(X_selected)[:, 1]\n",
    "        \n",
    "        # Apply threshold\n",
    "        predictions = (probabilities >= self.threshold).astype(int)\n",
    "        \n",
    "        # Risk levels\n",
    "        risk_levels = pd.cut(\n",
    "            probabilities,\n",
    "            bins=[0, 0.3, 0.6, 1.0],\n",
    "            labels=['Low', 'Medium', 'High']\n",
    "        )\n",
    "        \n",
    "        # Create results dataframe\n",
    "        results = pd.DataFrame({\n",
    "            'risk_probability': probabilities,\n",
    "            'risk_level': risk_levels,\n",
    "            'is_high_risk': predictions\n",
    "        }, index=X.index)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def predict_batch(self, X, batch_size=10000):\n",
    "        \"\"\"Predict in batches for large datasets\"\"\"\n",
    "        results = []\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            batch = X.iloc[i:i+batch_size]\n",
    "            batch_results = self.predict(batch)\n",
    "            results.append(batch_results)\n",
    "        \n",
    "        return pd.concat(results)\n",
    "    \n",
    "    def explain_prediction(self, X, top_n=5):\n",
    "        \"\"\"\n",
    "        Get top contributing features for each prediction.\n",
    "        Uses feature values as proxy for importance.\n",
    "        \n",
    "        For production: Integrate SHAP for true explanations.\n",
    "        \"\"\"\n",
    "        # This is simplified - in production use SHAP\n",
    "        feature_values = X[self.feature_names].values\n",
    "        feature_importance = np.abs(feature_values)\n",
    "        \n",
    "        explanations = []\n",
    "        for i in range(len(X)):\n",
    "            top_indices = np.argsort(feature_importance[i])[-top_n:][::-1]\n",
    "            top_features = [\n",
    "                {\n",
    "                    'feature': self.feature_names[idx],\n",
    "                    'value': float(feature_values[i][idx])\n",
    "                }\n",
    "                for idx in top_indices\n",
    "            ]\n",
    "            explanations.append(top_features)\n",
    "        \n",
    "        return explanations\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = OutageRiskPredictor()\n",
    "predictor.load_model(model_version=MODEL_VERSION)\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 3: TEST PREDICTION PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING PREDICTION PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load test data\n",
    "test_data = pd.read_csv(f'../models/test_sample_v{MODEL_VERSION}.csv')\n",
    "X_test_sample = test_data[feature_config['all_features']]\n",
    "y_test_sample = test_data['y_outage_next_48h']\n",
    "\n",
    "# Make predictions\n",
    "predictions = predictor.predict(X_test_sample)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"\\nðŸ“Š Test Sample Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_sample, predictions['is_high_risk']):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_sample, predictions['is_high_risk']))\n",
    "\n",
    "# Show sample predictions\n",
    "print(\"\\nðŸ“‹ Sample Predictions:\")\n",
    "sample_df = pd.concat([\n",
    "    test_data[['county']].head(10),\n",
    "    predictions.head(10)\n",
    "], axis=1)\n",
    "print(sample_df.to_string())\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 4: CREATE ACTION RECOMMENDER\n",
    "# ============================================================================\n",
    "\n",
    "class ActionRecommender:\n",
    "    \"\"\"Convert risk predictions to actionable recommendations\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.actions = {\n",
    "            'SME': [\n",
    "                {\n",
    "                    'priority': 1,\n",
    "                    'action': 'Reschedule heavy machinery to off-peak hours (2-5 PM)',\n",
    "                    'cost': 'Low',\n",
    "                    'impact': 'Avoid production halt',\n",
    "                    'triggers': ['high_risk', 'peak_hours']\n",
    "                },\n",
    "                {\n",
    "                    'priority': 2,\n",
    "                    'action': 'Pre-charge backup batteries to full capacity',\n",
    "                    'cost': 'Low',\n",
    "                    'impact': 'Ensure 4-6 hour continuity',\n",
    "                    'triggers': ['high_risk']\n",
    "                },\n",
    "                {\n",
    "                    'priority': 3,\n",
    "                    'action': 'Test and fuel backup generator',\n",
    "                    'cost': 'Medium',\n",
    "                    'impact': 'Extended backup capability',\n",
    "                    'triggers': ['high_risk', 'extended_window']\n",
    "                }\n",
    "            ],\n",
    "            'Telecom': [\n",
    "                {\n",
    "                    'priority': 1,\n",
    "                    'action': 'Switch critical towers to battery mode at 5:30 PM',\n",
    "                    'cost': 'Low',\n",
    "                    'impact': 'Prevent service interruption',\n",
    "                    'triggers': ['high_risk', 'planned_outage']\n",
    "                },\n",
    "                {\n",
    "                    'priority': 2,\n",
    "                    'action': 'Deploy mobile genset to high-traffic tower',\n",
    "                    'cost': 'High',\n",
    "                    'impact': 'Maintain coverage in critical area',\n",
    "                    'triggers': ['high_risk', 'extended_window']\n",
    "                },\n",
    "                {\n",
    "                    'priority': 3,\n",
    "                    'action': 'Alert field response team for rapid deployment',\n",
    "                    'cost': 'Low',\n",
    "                    'impact': 'Faster restoration if outage occurs',\n",
    "                    'triggers': ['high_risk']\n",
    "                }\n",
    "            ],\n",
    "            'Household': [\n",
    "                {\n",
    "                    'priority': 1,\n",
    "                    'action': 'Charge all phones and power banks',\n",
    "                    'cost': 'None',\n",
    "                    'impact': 'Stay connected during outage',\n",
    "                    'triggers': ['high_risk']\n",
    "                },\n",
    "                {\n",
    "                    'priority': 2,\n",
    "                    'action': 'Delay washing machine/dishwasher to after 10 PM',\n",
    "                    'cost': 'None',\n",
    "                    'impact': 'Reduce grid stress, avoid interruption',\n",
    "                    'triggers': ['high_risk', 'peak_hours']\n",
    "                },\n",
    "                {\n",
    "                    'priority': 3,\n",
    "                    'action': 'Prepare flashlights/candles, store drinking water',\n",
    "                    'cost': 'Low',\n",
    "                    'impact': 'Emergency preparedness',\n",
    "                    'triggers': ['high_risk', 'extended_window']\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def recommend(self, risk_df, persona='SME', county=None):\n",
    "        \"\"\"\n",
    "        Generate top 3 actions for high-risk periods.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        risk_df : pd.DataFrame\n",
    "            Output from OutageRiskPredictor.predict()\n",
    "        persona : str\n",
    "            One of ['SME', 'Telecom', 'Household']\n",
    "        county : str, optional\n",
    "            Filter recommendations for specific county\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame with recommendations\n",
    "        \"\"\"\n",
    "        # Filter high-risk periods\n",
    "        high_risk = risk_df[risk_df['is_high_risk'] == 1].copy()\n",
    "        \n",
    "        if len(high_risk) == 0:\n",
    "            return pd.DataFrame({\n",
    "                'message': ['No high-risk periods detected. Continue normal operations.']\n",
    "            })\n",
    "        \n",
    "        # Get actions for persona\n",
    "        actions = self.actions[persona]\n",
    "        \n",
    "        # For each high-risk period, assign top 3 actions\n",
    "        recommendations = []\n",
    "        for idx, row in high_risk.iterrows():\n",
    "            rec = {\n",
    "                'index': idx,\n",
    "                'risk_probability': row['risk_probability'],\n",
    "                'risk_level': row['risk_level']\n",
    "            }\n",
    "            \n",
    "            # Add top 3 actions\n",
    "            for i, action in enumerate(actions[:3], 1):\n",
    "                rec[f'action_{i}'] = action['action']\n",
    "                rec[f'action_{i}_cost'] = action['cost']\n",
    "                rec[f'action_{i}_impact'] = action['impact']\n",
    "            \n",
    "            recommendations.append(rec)\n",
    "        \n",
    "        return pd.DataFrame(recommendations)\n",
    "\n",
    "# Test recommender\n",
    "recommender = ActionRecommender()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING ACTION RECOMMENDER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get recommendations for sample\n",
    "recommendations_sme = recommender.recommend(predictions.head(20), persona='SME')\n",
    "print(\"\\nðŸ“‹ Sample Recommendations (SME):\")\n",
    "print(recommendations_sme[['index', 'risk_probability', 'action_1', 'action_2']].head())\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 5: CREATE TIERED ALERT SYSTEM\n",
    "# ============================================================================\n",
    "\n",
    "def create_tiered_alerts(predictions, budget_tiers=None):\n",
    "    \"\"\"\n",
    "    Create tiered alert system based on risk probability.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predictions : pd.DataFrame\n",
    "        Output from predictor.predict()\n",
    "    budget_tiers : dict\n",
    "        Alert budgets per tier, e.g. {'critical': 0.05, 'high': 0.10, 'medium': 0.20}\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame with alert tiers assigned\n",
    "    \"\"\"\n",
    "    if budget_tiers is None:\n",
    "        budget_tiers = {\n",
    "            'critical': 0.05,  # Top 5% - Emergency response\n",
    "            'high': 0.10,      # Top 10% - Proactive measures\n",
    "            'medium': 0.20,    # Top 20% - Monitoring\n",
    "        }\n",
    "    \n",
    "    results = predictions.copy()\n",
    "    \n",
    "    # Calculate percentile thresholds\n",
    "    critical_threshold = np.quantile(results['risk_probability'], 1 - budget_tiers['critical'])\n",
    "    high_threshold = np.quantile(results['risk_probability'], 1 - budget_tiers['high'])\n",
    "    medium_threshold = np.quantile(results['risk_probability'], 1 - budget_tiers['medium'])\n",
    "    \n",
    "    # Assign tiers\n",
    "    results['alert_tier'] = 'low'\n",
    "    results.loc[results['risk_probability'] >= medium_threshold, 'alert_tier'] = 'medium'\n",
    "    results.loc[results['risk_probability'] >= high_threshold, 'alert_tier'] = 'high'\n",
    "    results.loc[results['risk_probability'] >= critical_threshold, 'alert_tier'] = 'critical'\n",
    "    \n",
    "    # Recommended actions\n",
    "    results['recommended_action'] = results['alert_tier'].map({\n",
    "        'critical': 'IMMEDIATE ACTION - Deploy emergency resources',\n",
    "        'high': 'PROACTIVE - Implement backup plans',\n",
    "        'medium': 'MONITOR - Increase vigilance',\n",
    "        'low': 'NORMAL - Continue operations'\n",
    "    })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test tiered alerts\n",
    "alerts = create_tiered_alerts(predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIERED ALERT SYSTEM\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nAlert Distribution:\")\n",
    "print(alerts['alert_tier'].value_counts())\n",
    "print(\"\\nSample Critical Alerts:\")\n",
    "print(alerts[alerts['alert_tier'] == 'critical'][['risk_probability', 'alert_tier', 'recommended_action']].head())\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 6: SAVE DEPLOYMENT ARTIFACTS\n",
    "# ============================================================================\n",
    "\n",
    "# Save predictor class\n",
    "import cloudpickle\n",
    "\n",
    "with open('../scripts/predictor.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(predictor, f)\n",
    "print(\"\\nâœ… Predictor saved to ../scripts/predictor.pkl\")\n",
    "\n",
    "# Save recommender class\n",
    "with open('../scripts/recommender.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(recommender, f)\n",
    "print(\"âœ… Recommender saved to ../scripts/recommender.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DEPLOYMENT PREPARATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nâœ… Ready for deployment!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Create API (FastAPI)\")\n",
    "print(\"2. Create Dashboard (Streamlit)\")\n",
    "print(\"3. Set up data pipeline\")\n",
    "print(\"4. Deploy to production\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.16 (GPU)",
   "language": "python",
   "name": "tf-216"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
